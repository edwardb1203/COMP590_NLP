{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/edwardb1203/COMP590_NLP/blob/main/Copy_of_hw3_neural_language_mlp_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rpDwZqpnQ2iw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e90526ce-1c47-4215-e98a-79f6f3203369"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f246815d330>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import argparse\n",
        "from dataclasses import dataclass\n",
        "from typing import List\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "torch.manual_seed(1337)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the tiny Shakespeare dataset\n",
        "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
      ],
      "metadata": {
        "id": "EZhswgQ0d62Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d986f417-c3db-4df3-b767-a70edc7be041"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-07 00:45:56--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115394 (1.1M) [text/plain]\n",
            "Saving to: ‘input.txt’\n",
            "\n",
            "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-04-07 00:45:56 (103 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the text file\n",
        "input_file_path = os.path.join(os.path.dirname('./'), 'input.txt')\n",
        "if not os.path.exists(input_file_path):\n",
        "    data_url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
        "    with open(input_file_path, 'w') as f:\n",
        "        f.write(requests.get(data_url).text)\n"
      ],
      "metadata": {
        "id": "-QeF9ymlQ6ws"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Examine the dataset\n",
        "with open(input_file_path, 'r') as f:\n",
        "    data = f.read()\n",
        "print(f\"length of dataset in characters: {len(data):,}\")"
      ],
      "metadata": {
        "id": "kWWDOd3ACfXK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deb35401-6e17-407a-eab9-608a9a7bbb19"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters: 1,115,394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the vocabulary (i.e. the unique chars)\n",
        "# chars should be a SORTED list of unique characters in the data object\n",
        "\n",
        "chars = sorted(set([*data]))\n",
        "\n",
        "vocab_size = len(chars)\n",
        "print(\"all the unique characters:\", ''.join(chars))\n",
        "print(f\"vocab size: {vocab_size:,}\")"
      ],
      "metadata": {
        "id": "jUA8Gt_-Cdmm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7373d11b-4ef9-4592-9706-6dfb4dcc64a7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "all the unique characters: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "vocab size: 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# a mapping from character to integer\n",
        "ctoi = {s:i for i,s in enumerate(chars)}\n",
        "\n",
        "\n",
        "# a mapping from integer to character\n",
        "# that reverses the ctoi constructed above\n",
        "itoc =  {num: char for char, num in ctoi.items()}"
      ],
      "metadata": {
        "id": "F4CQR0M-e40N"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode the dataset\n",
        "def encode(text):\n",
        "  # input: a string\n",
        "  # output: a list of integers that represents each character in the string\n",
        "  return [ctoi[s] for s in text]\n",
        "\n",
        "\n",
        "# decode the dataset\n",
        "def decode(rep):\n",
        "  # input:  a list of integers \n",
        "  # output: a string that was represented by the input list of integers\n",
        "  return [itoc[i] for i in rep]\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "g-4LMZRJgc1A"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the train and test splits\n",
        "n = len(data)\n",
        "train_data = data[:int(n*0.9)]\n",
        "val_data = data[int(n*0.9):]\n",
        "\n",
        "# encode both to integers\n",
        "train_ids = torch.tensor(encode(train_data),dtype=torch.long)\n",
        "val_ids = torch.tensor(encode(val_data),dtype=torch.long)"
      ],
      "metadata": {
        "id": "jtpc1hbyhvyu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_ids))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5izBY-Z2sop",
        "outputId": "f7ab3d9d-af27-48c3-c826-02e206d13864"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1003854\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a block size, batch_size, and construct the batch\n",
        "# Create the training/test datasets\n",
        "# Recall that we want to take in the past block_size characeters (where we \n",
        "# choose block_size) and output the next charcater\n",
        "block_size = 32\n",
        "\n",
        "# Args: \n",
        "#   split: set to train when want to use train_ids, set to val when want to use\n",
        "#          val_ids\n",
        "#   batch_size: the size of the batch for training\n",
        "# Outputs:\n",
        "#   x: training/val data, where each row is a list of previous character ids\n",
        "#   y: training/val ground truth, where each entry is the ground-truth character\n",
        "#      id for the current character\n",
        "# \n",
        "# In essence, we want to use the list of previous character ids ot predict the \n",
        "# current character id\n",
        "\n",
        "# Note that the output x and y should be torch tensors. \n",
        "\n",
        "def get_batch(split,batch_size):\n",
        "  data = train_ids if split=='train' else val_ids\n",
        "  # This line of code generates a random index for each batch in the training or validation data.\n",
        "  # It makes a tensor ix of shape (batch_size, ), where each element is a random integer between 0 and len(data) - block_size.\n",
        "  ix = torch.randint(len(data)-block_size,(batch_size,))\n",
        "  # creates a column vector from the ix tensor, and the expression torch.arange(block_size) creates a row vector of values\n",
        "  # from 0 to block_size. Adding these two tensors creates a matrix where each row is a sequence of character IDs from the original data.\n",
        "  x = data[ix[:, None] + torch.arange(block_size)]\n",
        "  # makes a tensor containing the indices of the last character in each sequence.\n",
        "  # Indexing data with this tensor returns the ground-truth output for each input sequence.\n",
        "  y = data[ix + block_size]\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "qDmjcZJIjKo2"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the embedding dictionary\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "n_embd = 80\n",
        "n_embd2 = 256\n",
        "\n",
        "class MLP_neural_language(nn.Module):\n",
        "    \"\"\"\n",
        "    takes the previous block_size tokens, encodes them with a lookup table,\n",
        "    concatenates the vectors and predicts the next token with an MLP.\n",
        "    Reference:\n",
        "    Bengio et al. 2003 https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, block_size,vocab_size,n_embd,n_embd2):\n",
        "        super().__init__()\n",
        "        self.block_size =block_size\n",
        "        self.vocab_size =vocab_size\n",
        "        self.wte = nn.Embedding(vocab_size,n_embd) \n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(self.block_size *n_embd,n_embd2),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(n_embd2, self.vocab_size)\n",
        "        )\n",
        "\n",
        "    def get_block_size(self):\n",
        "        return self.block_size\n",
        "\n",
        "    def forward(self, inputs_idx, targets=None):\n",
        "        inputs_embd = self.wte(inputs_idx)\n",
        "        inputs_embd = inputs_embd.reshape(inputs_embd.shape[0],-1)\n",
        "        logits = self.mlp(inputs_embd)\n",
        "        # if we are given some desired targets also calculate the loss\n",
        "        loss = None\n",
        "        if targets is not None:\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1))\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "\n",
        "m = MLP_neural_language(block_size,vocab_size,n_embd,n_embd2)"
      ],
      "metadata": {
        "id": "A8KmgsegmpyF"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# a simple training loop\n",
        "def train_model(m, block_size):\n",
        "  m = m.to('cuda')\n",
        "  batch_size = 4096\n",
        "  num_epochs = 30\n",
        "  num_batches = 256\n",
        "  optimizer = torch.optim.Adam(m.parameters(),lr=1e-3)\n",
        "  for i in range(num_epochs):\n",
        "    epoch_loss = 0.0\n",
        "    for steps in range(num_batches):\n",
        "      optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "      # sample a batch of data\n",
        "      xb,yb = get_batch('train', batch_size)\n",
        "\n",
        "      xb = xb.to('cuda')\n",
        "      yb = yb.to('cuda')\n",
        "\n",
        "      # evaluate the loss\n",
        "      logits, loss = m.forward(xb,yb)\n",
        "\n",
        "      loss.backward()\n",
        "    \n",
        "      optimizer.step()\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "\n",
        "    # print(epoch_loss/num_batches)\n",
        "\n",
        "  print(\"Block size is: \" + str(block_size) + \" and loss is: \" + str(loss.item()))"
      ],
      "metadata": {
        "id": "CGG_irmT9joZ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "block_size = 128\n",
        "m = MLP_neural_language(block_size,vocab_size,n_embd,n_embd2)\n",
        "train_model(m, block_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBLr0bFpTk5C",
        "outputId": "54289363-ba80-45a3-a279-20ac113877e4"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block size is: 128 and loss is: 0.5276082754135132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # C \n",
        "# # context sizes to experiment with\n",
        "# context_sizes = [2, 16, 64, 128]\n",
        "\n",
        "# # train the language model for each context size\n",
        "# for block_size in context_sizes:\n",
        "#   # initialize the model again\n",
        "#   m = MLP_neural_language(block_size,vocab_size,n_embd,n_embd2)\n",
        "\n",
        "#   # train the model with the new context size and eval loss\n",
        "#   train_model(m, block_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rObxgpXFM2t8",
        "outputId": "dac24293-f168-49f0-dff3-6e3d2a6d65f1"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Block size is: 2 and loss is: 1.8821747303009033\n",
            "Block size is: 16 and loss is: 1.3281852006912231\n",
            "Block size is: 64 and loss is: 0.8763432502746582\n",
            "Block size is: 128 and loss is: 0.5356072783470154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generation\n",
        "# We use the first block_size number of characters in the val set to start \n",
        "# generating Shakespear-styled writings. \n",
        "\n",
        "m = m.to('cpu')\n",
        "limit = 1000\n",
        "# the first block_size number of characters in val_ids\n",
        "context = val_ids[:block_size].tolist()\n",
        "generation = context\n",
        "\n",
        "for i in range(limit):\n",
        "  # convert to tensor\n",
        "  context_tensor = torch.tensor(context).unsqueeze(0)\n",
        "  # output is a tensor of shape (1, vocab_size)\n",
        "  output = m(context_tensor)\n",
        "  # next character is the argmax of the output tensor along the second dimension\n",
        "  pred = output[0].argmax(dim=1).item()\n",
        "  # update context by appending the generated character and removing the first character\n",
        "  context.append(pred)\n",
        "  context = context[1:]\n",
        "  # Append the generated character to the generation list\n",
        "  generation.append(pred)\n"
      ],
      "metadata": {
        "id": "tS4rshzWS-Cm"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decode the generation and see what the AI came up with :)\n",
        "print(' '.join(decode(generation)))\n",
        "blcok_size_32 = ' '.join(decode(generation))"
      ],
      "metadata": {
        "id": "YdvDnz7FUvUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20ef6f81-9f86-4995-b284-533c7ceca945"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "? \n",
            " \n",
            " G R E M I O : \n",
            " G o o d   m o r r o w ,   n e i g h b o u r r   i n   t h e   f i e l d   w e   w a s t i n g   b l a w   h i s   d e s t , \n",
            " A n d   t r u e   s e r v i c e   o f   i n   t h e   s i c k   t o   m y   s p e a k   t o   c a l l s . \n",
            " \n",
            " K I N G   E D W A R D   I V : \n",
            " A l a s ,   M a r k   t h e   b e s t a t e   a n   o f   a n   i n t i o n   o f   d e a t h , \n",
            " A n d   b e a r   t h e e   a t   t h y   s t a t   o f   h i m e , \n",
            " W h o   c a n n o t   w h a t   s h o w   t o   y o u r   g a n d e d \n",
            " T o   s i n   t h e   d a y   t h e   c o u l d   n o t   s o u l   t e n t e r   m a i d \n",
            " A   m a n   a n d   t h e   s e e n   t o   y o u r   t h i n g   t h e i r   o w n \n",
            " s p e a k   t h e   s t r a i n   o n c l e s   n o t   e s s e e d   t o   y o u r   t h e   f a t h e r   c a n n o t   d o n e   t o   s u c h \n",
            " a n d   n o t   s o   d e a t h   t h e   k i n g   o f   h i s   f a i t   b e f o r e   h e a d   m y   l i f e , \n",
            " A n d   m a k e   m y   l e a v e   l i g h t   t h e m   i n   t h e e , \n",
            " W h e n   t h e   s h a l l   b e   t h i s   b u t   t o   t h e   c h i l d r e n c e   a n d   t h e y   d e c l i n g   f a l l \n",
            " w e r e   t h e y   s t a r s   s h a l l   c o m e   t o   d i e . \n",
            " \n",
            " K I N G   R I C H A R D   I I : \n",
            " W e   h e   c l a t g e r   m a n ,   t h a t   h a t h   s o m e   p a r t   t h e m . \n",
            " \n",
            " C O M I N I U S : \n",
            " W e   h e   w e l l ,   w e   w o u l d   t e l l   f e t t   a c c e p e s i t e d : \n",
            " T h e   f r o w n   t h i s   f r o m   t h e   t i m e   t o   m e . \n",
            " \n",
            " M E N E N I U S : \n",
            " W h a t   y o u   w e   m i n e   b e s t   s e e n   a n   o f   h e a r t \n",
            " T h a t   w h e r e   u p   t h a t   e v e r   t o   t h e   s i n c e , \n",
            " T h a t   d o v e   t h e e   t h a t   m a y   s t r a n g e r   s t r e n g e   t o   s u c h   a s   t h e   w o r l d , \n",
            " T h a t   t h o u   h a s t   t h o u   h i s   c o u n t r y ' d   i t . \n",
            " \n",
            " K I N G   R I C H A R D   I I : \n",
            " T h o u   h a s t   s o o r   s t a y   t h e   e a r   t h e   m o r e   t h e r e . \n",
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(' '.join(decode(generation)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpMBUi6JTAV9",
        "outputId": "add4ea8e-8285-41f8-cb59-7cf716fbcff5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "? \n",
            " \n",
            " G R E M I O : \n",
            " G o o d   m o r r o w ,   n e i g h b o u r   B a p t i s t a . \n",
            " \n",
            " B A P T I S T A : \n",
            " G o o d   m o r r o w ,   n e i g h b o u r   G r e m i o . \n",
            " G o d   s a v e   y o u ,   g e n t l e m e n ! \n",
            " \n",
            " P E T R U C H I O : \n",
            " A n d   y o o u ,   s i n   i s   s l u r e ;   I   s c u l l   t a t   t h e   h e   o n e   t o r r . \n",
            " \n",
            " G U R E T : \n",
            " A y ,   y f t r i a n   s i k e   m y   l i f ,   s o   n o g e :   t h e y ' g . \n",
            " \n",
            " N E E N O : \n",
            " B e c i s ,   m e t   n o t h e r ,   w a y   d o   i f   t h e   n e s . \n",
            " \n",
            " K I N G   R I C H A R D   I I I : \n",
            " S e e   s h y   d i d e s t   b a k i n g ,   E x t e r a n - g e   i t   n a y \n",
            " u n t   d o n e   p a t i r e s t .   G o a t l ;   a t   I   c o m a n g   w e t h \n",
            " s h o u l   b e   s e c e   t h a t   p r e c e ,   I   c r u c h e r   t h e m , \n",
            " W h a t   s o   y o u r   m i s t   o f   t h u t ?   W a t ,   t h e   n o t   d o m e s , \n",
            " A n d   a l l   t h o u   m a k e t '   t h e   b e   m a n   a m e n   t h e e , \n",
            " A s   I s   R o n e w   o f   i t   t h a t   o f   m y   d a y   t r e s t , \n",
            " M y   d a n g e e d   t o   b y \n",
            " D e e s   n i g h t   w i t h   s t r e a t   f o r c e s s u l f o r   i n   t h e   h e r d . \n",
            " \n",
            " M A R I A U S : \n",
            " F o w   t h a l l   b e a r s   t h e y   w o r d   n a c e s : \n",
            " T h e   w i t h   h e n l e ,   t h a t   s h o u   h i m s e r !   w h e n ,   h e a i n ,   s o m e ! \n",
            " T h i r '   t h e   h a t e   e n f e l d s e ,   t h a n \n",
            " T h e s e   c o u r   w o n e ,   a n d   h e r   y o u r   g r a c k ' d \n",
            " T h e s t a k e   t h e   g a r s ,   I   d m a r r   o f   m y   b r i e s l : \n",
            " C a n d e r e d ,   t h a s   w a s l i m e n   a n   y o u   t h a t   h e r ' d ; \n",
            " A n d   d e w i l l   d o r o u t   t h y   w a y ;   a n d   a   t a y   m e s s e n . \n",
            " \n",
            " B O R K I N I ,   n a u l   m a y   o r   a n   t h e p   d e a s . \n",
            " \n",
            " D U K E   V I N C E N T I O : \n",
            " S t i r t   o m a n n   t o o   a n d a y ;   h i d   o f   y o u   n u s t   i n g a y , \n",
            " T h e n   b y   c o t r e n t   R o c e - f a r   t h o u s   b e i t i s   f o r n , \n",
            " a s   d o t h   o u n d s   n o t   t h e a   k i n g   o f   i t   c r a n c e s , \n",
            " T h i s   y o u n t . \n",
            " \n",
            " D U S C o n F   Y o u   k e s t r i c k   t o   b\n"
          ]
        }
      ]
    }
  ]
}
